#!/usr/bin/env python3
"""
Raspberry Piä¸Šã§å‹•ä½œã™ã‚‹ç†Šæ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
TensorFlow Lite ã¾ãŸã¯ ONNX Runtime ã«ã‚ˆã‚‹æ¨è«–

å¿…è¦ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢:
- Raspberry Pi 4/5 (4GBä»¥ä¸Šæ¨å¥¨)
- Raspberry Pi Camera Module v2/v3 ã¾ãŸã¯ USB Webã‚«ãƒ¡ãƒ©
- ã‚ªãƒ—ã‚·ãƒ§ãƒ³: Coral Edge TPU (æ¨è«–é«˜é€ŸåŒ–)
"""

import os
import sys
import time
import json
import logging
import threading
import queue
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Optional, List, Tuple, Callable

import yaml
import requests
import numpy as np

# ã‚«ãƒ¡ãƒ©ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆç’°å¢ƒã«å¿œã˜ã¦é¸æŠï¼‰
try:
    from picamera2 import Picamera2
    CAMERA_TYPE = "picamera2"
except ImportError:
    try:
        import cv2
        CAMERA_TYPE = "opencv"
    except ImportError:
        CAMERA_TYPE = None
        print("è­¦å‘Š: ã‚«ãƒ¡ãƒ©ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆç’°å¢ƒã«å¿œã˜ã¦é¸æŠï¼‰
try:
    import tflite_runtime.interpreter as tflite
    INFERENCE_ENGINE = "tflite"
except ImportError:
    try:
        import onnxruntime as ort
        INFERENCE_ENGINE = "onnx"
    except ImportError:
        INFERENCE_ENGINE = None
        print("è­¦å‘Š: æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# Coral Edge TPUï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from pycoral.utils import edgetpu
    from pycoral.adapters import common, detect
    HAS_CORAL = True
except ImportError:
    HAS_CORAL = False


# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class Detection:
    """æ¤œçŸ¥çµæœ"""
    timestamp: str
    device_id: str
    latitude: float
    longitude: float
    confidence: float
    class_name: str
    bbox: Optional[List[int]]  # [x1, y1, x2, y2]
    image_path: Optional[str]
    

@dataclass
class Config:
    """è¨­å®š"""
    device_id: str
    latitude: float
    longitude: float
    model_path: str
    labels_path: str
    server_url: str
    detection_threshold: float
    target_classes: List[str]
    capture_interval: float
    image_save_dir: str
    use_coral: bool
    camera_resolution: Tuple[int, int]


def load_config(config_path: str = "config.yaml") -> Config:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    with open(config_path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    
    return Config(
        device_id=data.get("device_id", "unknown"),
        latitude=data.get("latitude", 0.0),
        longitude=data.get("longitude", 0.0),
        model_path=data.get("model_path", "models/bear_detector.tflite"),
        labels_path=data.get("labels_path", "models/labels.txt"),
        server_url=data.get("server_url", "http://localhost:8000"),
        detection_threshold=data.get("detection_threshold", 0.6),
        target_classes=data.get("target_classes", ["bear", "ã‚¯ãƒ"]),
        capture_interval=data.get("capture_interval", 1.0),
        image_save_dir=data.get("image_save_dir", "captures"),
        use_coral=data.get("use_coral", False) and HAS_CORAL,
        camera_resolution=tuple(data.get("camera_resolution", [640, 480]))
    )


class CameraCapture:
    """ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, resolution: Tuple[int, int] = (640, 480)):
        self.resolution = resolution
        self.camera = None
        
        if CAMERA_TYPE == "picamera2":
            self._init_picamera2()
        elif CAMERA_TYPE == "opencv":
            self._init_opencv()
        else:
            raise RuntimeError("åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¡ãƒ©ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _init_picamera2(self):
        """Picamera2ã®åˆæœŸåŒ–"""
        self.camera = Picamera2()
        config = self.camera.create_preview_configuration(
            main={"size": self.resolution, "format": "RGB888"}
        )
        self.camera.configure(config)
        self.camera.start()
        time.sleep(2)  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        logger.info("Picamera2ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def _init_opencv(self):
        """OpenCVã®åˆæœŸåŒ–"""
        self.camera = cv2.VideoCapture(0)
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, self.resolution[0])
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, self.resolution[1])
        logger.info("OpenCV VideoCapture ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def capture(self) -> Optional[np.ndarray]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£"""
        if CAMERA_TYPE == "picamera2":
            return self.camera.capture_array()
        elif CAMERA_TYPE == "opencv":
            ret, frame = self.camera.read()
            if ret:
                return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return None
    
    def close(self):
        """ã‚«ãƒ¡ãƒ©ã‚’è§£æ”¾"""
        if CAMERA_TYPE == "picamera2" and self.camera:
            self.camera.stop()
        elif CAMERA_TYPE == "opencv" and self.camera:
            self.camera.release()


class BearDetector:
    """ç†Šæ¤œçŸ¥å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.labels = self._load_labels()
        self.interpreter = None
        
        if config.use_coral:
            self._init_coral()
        elif INFERENCE_ENGINE == "tflite":
            self._init_tflite()
        elif INFERENCE_ENGINE == "onnx":
            self._init_onnx()
        else:
            raise RuntimeError("åˆ©ç”¨å¯èƒ½ãªæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _load_labels(self) -> List[str]:
        """ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config.labels_path, "r", encoding="utf-8") as f:
                return [line.strip() for line in f.readlines()]
        except FileNotFoundError:
            logger.warning("ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
            return ["background", "bear"]
    
    def _init_tflite(self):
        """TensorFlow Liteã®åˆæœŸåŒ–"""
        self.interpreter = tflite.Interpreter(model_path=self.config.model_path)
        self.interpreter.allocate_tensors()
        
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
        self.input_shape = self.input_details[0]['shape'][1:3]
        logger.info(f"TFLite ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config.model_path}")
        logger.info(f"å…¥åŠ›ã‚µã‚¤ã‚º: {self.input_shape}")
    
    def _init_coral(self):
        """Coral Edge TPUã®åˆæœŸåŒ–"""
        self.interpreter = edgetpu.make_interpreter(self.config.model_path)
        self.interpreter.allocate_tensors()
        
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
        self.input_shape = self.input_details[0]['shape'][1:3]
        logger.info(f"Coral Edge TPU ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    def _init_onnx(self):
        """ONNX Runtimeã®åˆæœŸåŒ–"""
        self.session = ort.InferenceSession(
            self.config.model_path,
            providers=['CPUExecutionProvider']
        )
        
        input_info = self.session.get_inputs()[0]
        self.input_name = input_info.name
        self.input_shape = input_info.shape[2:4]  # [batch, channels, height, width]
        logger.info(f"ONNX ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config.model_path}")
    
    def preprocess(self, frame: np.ndarray) -> np.ndarray:
        """å‰å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚ºã€æ­£è¦åŒ–ï¼‰"""
        import cv2
        
        # ãƒªã‚µã‚¤ã‚º
        resized = cv2.resize(frame, tuple(self.input_shape[::-1]))
        
        # æ­£è¦åŒ–ï¼ˆãƒ¢ãƒ‡ãƒ«ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        normalized = resized.astype(np.float32) / 255.0
        
        # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
        if INFERENCE_ENGINE == "onnx":
            # ONNX: [batch, channels, height, width]
            return np.transpose(normalized, (2, 0, 1))[np.newaxis, ...]
        else:
            # TFLite: [batch, height, width, channels]
            return np.expand_dims(normalized, axis=0)
    
    def detect(self, frame: np.ndarray) -> List[Tuple[str, float, List[int]]]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œ
        Returns: [(class_name, confidence, [x1, y1, x2, y2]), ...]
        """
        input_data = self.preprocess(frame)
        
        if INFERENCE_ENGINE == "tflite" or self.config.use_coral:
            self.interpreter.set_tensor(
                self.input_details[0]['index'],
                input_data.astype(np.float32)
            )
            self.interpreter.invoke()
            
            # å‡ºåŠ›ã®å–å¾—ï¼ˆãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«ä¾å­˜ï¼‰
            boxes = self.interpreter.get_tensor(self.output_details[0]['index'])
            classes = self.interpreter.get_tensor(self.output_details[1]['index'])
            scores = self.interpreter.get_tensor(self.output_details[2]['index'])
            
        elif INFERENCE_ENGINE == "onnx":
            outputs = self.session.run(None, {self.input_name: input_data})
            boxes, scores, classes = outputs[0], outputs[1], outputs[2]
        
        # çµæœã‚’ãƒ‘ãƒ¼ã‚¹
        detections = []
        h, w = frame.shape[:2]
        
        for i in range(len(scores[0])):
            score = float(scores[0][i])
            if score < self.config.detection_threshold:
                continue
            
            class_id = int(classes[0][i])
            class_name = self.labels[class_id] if class_id < len(self.labels) else "unknown"
            
            # å¯¾è±¡ã‚¯ãƒ©ã‚¹ã‹ãƒã‚§ãƒƒã‚¯
            if class_name.lower() not in [c.lower() for c in self.config.target_classes]:
                continue
            
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ï¼ˆæ­£è¦åŒ–åº§æ¨™ â†’ ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ï¼‰
            box = boxes[0][i]
            x1 = int(box[1] * w)
            y1 = int(box[0] * h)
            x2 = int(box[3] * w)
            y2 = int(box[2] * h)
            
            detections.append((class_name, score, [x1, y1, x2, y2]))
        
        return detections


class DetectionReporter:
    """æ¤œçŸ¥çµæœã‚’ã‚µãƒ¼ãƒãƒ¼ã«å ±å‘Š"""
    
    def __init__(self, config: Config):
        self.config = config
        self.queue = queue.Queue()
        self.running = True
        
        # é€ä¿¡ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        self.thread = threading.Thread(target=self._send_loop, daemon=True)
        self.thread.start()
    
    def report(self, detection: Detection):
        """æ¤œçŸ¥çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        self.queue.put(detection)
    
    def _send_loop(self):
        """é€ä¿¡ãƒ«ãƒ¼ãƒ—"""
        while self.running:
            try:
                detection = self.queue.get(timeout=1.0)
                self._send(detection)
            except queue.Empty:
                continue
    
    def _send(self, detection: Detection):
        """ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡"""
        try:
            url = f"{self.config.server_url}/api/detections"
            response = requests.post(
                url,
                json=asdict(detection),
                timeout=10
            )
            if response.status_code == 200:
                logger.info(f"æ¤œçŸ¥çµæœã‚’é€ä¿¡ã—ã¾ã—ãŸ: {detection.device_id}")
            else:
                logger.warning(f"é€ä¿¡ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        except requests.RequestException as e:
            logger.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒªãƒˆãƒ©ã‚¤ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            self.queue.put(detection)
            time.sleep(5)
    
    def stop(self):
        """é€ä¿¡ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢"""
        self.running = False
        self.thread.join(timeout=5)


def save_detection_image(
    frame: np.ndarray,
    detection: Tuple[str, float, List[int]],
    save_dir: str,
    device_id: str
) -> str:
    """æ¤œçŸ¥ç”»åƒã‚’ä¿å­˜"""
    import cv2
    
    Path(save_dir).mkdir(parents=True, exist_ok=True)
    
    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
    class_name, confidence, bbox = detection
    x1, y1, x2, y2 = bbox
    
    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (0, 0, 255), 2)
    cv2.putText(
        frame_bgr,
        f"{class_name}: {confidence:.2f}",
        (x1, y1 - 10),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.5,
        (0, 0, 255),
        2
    )
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{device_id}_{timestamp}.jpg"
    filepath = str(Path(save_dir) / filename)
    
    cv2.imwrite(filepath, frame_bgr)
    logger.info(f"ç”»åƒã‚’ä¿å­˜: {filepath}")
    
    return filepath


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    # è¨­å®šèª­ã¿è¾¼ã¿
    config_path = Path(__file__).parent / "config.yaml"
    if not config_path.exists():
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        logger.info("config.yaml.example ã‚’å‚è€ƒã«ä½œæˆã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    config = load_config(str(config_path))
    logger.info(f"ãƒ‡ãƒã‚¤ã‚¹ID: {config.device_id}")
    logger.info(f"ä½ç½®: ({config.latitude}, {config.longitude})")
    
    # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆæœŸåŒ–
    try:
        camera = CameraCapture(config.camera_resolution)
        detector = BearDetector(config)
        reporter = DetectionReporter(config)
    except Exception as e:
        logger.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)
    
    logger.info("ç†Šæ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™...")
    
    try:
        while True:
            start_time = time.time()
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
            frame = camera.capture()
            if frame is None:
                logger.warning("ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")
                time.sleep(0.5)
                continue
            
            # æ¤œçŸ¥å®Ÿè¡Œ
            detections = detector.detect(frame)
            
            # æ¤œçŸ¥ãŒã‚ã‚Œã°å ±å‘Š
            for class_name, confidence, bbox in detections:
                logger.warning(f"ğŸ» ç†Šã‚’æ¤œçŸ¥! ä¿¡é ¼åº¦: {confidence:.2f}")
                
                # ç”»åƒã‚’ä¿å­˜
                image_path = save_detection_image(
                    frame, (class_name, confidence, bbox),
                    config.image_save_dir, config.device_id
                )
                
                # æ¤œçŸ¥çµæœã‚’ä½œæˆ
                detection = Detection(
                    timestamp=datetime.utcnow().isoformat() + "Z",
                    device_id=config.device_id,
                    latitude=config.latitude,
                    longitude=config.longitude,
                    confidence=confidence,
                    class_name=class_name,
                    bbox=bbox,
                    image_path=image_path
                )
                
                # ã‚µãƒ¼ãƒãƒ¼ã«å ±å‘Š
                reporter.report(detection)
            
            # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«èª¿æ•´
            elapsed = time.time() - start_time
            sleep_time = max(0, config.capture_interval - elapsed)
            time.sleep(sleep_time)
            
    except KeyboardInterrupt:
        logger.info("çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’å—ä¿¡")
    finally:
        camera.close()
        reporter.stop()
        logger.info("ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
